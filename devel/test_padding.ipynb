{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "from rd3d.datasets import build_dataloader\n",
    "from rd3d.models import build_detector\n",
    "from rd3d.core import Config\n",
    "from rd3d import PROJECT_ROOT\n",
    "from rd3d.core.base import ScopeTimer\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "acc = accelerate.Accelerator()\n",
    "\n",
    "from rd3d.models.dense_heads.point_seg import PointSegmentor\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class VoxelGrouper(torch.nn.Module):\n",
    "    def __init__(self, grid_size, group_size):\n",
    "        super().__init__()\n",
    "        self.grid_size = torch.tensor(grid_size).cuda()\n",
    "        self.group_size = group_size\n",
    "\n",
    "    @staticmethod\n",
    "    def padding(bs, indices, group_size, bid_num_cum):\n",
    "        \"\"\"\n",
    "        (n1,...,nb)\n",
    "        (ng1,...,ngb)\n",
    "\n",
    "        \"\"\"\n",
    "        elems_num_flat = bid_num_cum[1:] - bid_num_cum[:-1]\n",
    "        elems_num_group = torch.div(elems_num_flat + group_size - 1, group_size, rounding_mode='floor') * group_size\n",
    "        elems_num_pad = elems_num_group - elems_num_flat\n",
    "\n",
    "        indices_padding_list = []\n",
    "        for i in range(bs):\n",
    "            indices_padding_list.append(indices[:, bid_num_cum[i]:bid_num_cum[i + 1]])\n",
    "            if elems_num_pad[i] > 0:\n",
    "                indices_padding_list.append(indices_padding_list[-1][:, -elems_num_pad[i]:])\n",
    "        indices_padding = torch.cat(indices_padding_list, dim=-1)\n",
    "        return indices_padding\n",
    "\n",
    "    @staticmethod\n",
    "    def indices_convert_from_to(indices2, indices1):\n",
    "        indices2_in_original = torch.empty_like(indices1)\n",
    "        indices2_in_original[indices2] = torch.arange(indices2.shape[0], device=indices2.device)\n",
    "        indices2_in_original = indices2_in_original[indices1]\n",
    "        return indices2_in_original\n",
    "\n",
    "    def forward(self, vox_coors, vox_numbs):\n",
    "        \"\"\"\n",
    "\n",
    "        each block handle a batch sample.\n",
    "\n",
    "        \"\"\"\n",
    "        bid, vox_coors = torch.split(vox_coors, [1, 3], dim=-1)\n",
    "        bid = bid.view(-1)\n",
    "        order = sfc.min_required_order(vox_coors)\n",
    "        bs_info = torch.nn.functional.pad(torch.bincount(bid), (1, 0), mode='constant', value=0)\n",
    "        bid_num_cum = torch.cumsum(bs_info, dim=0)\n",
    "        bs = bid_num_cum.shape[0] - 1\n",
    "\n",
    "        vox_coors = torch.cat((vox_coors, self.grid_size - vox_coors)).int()\n",
    "        codes = sfc.hilbert_curve_encoder(vox_coors, order)[None, :].view(2, -1)\n",
    "        codes += bid << order * 3\n",
    "        indices = torch.argsort(codes, dim=-1)\n",
    "        return indices\n",
    "        indices1_group, indices2_group = self.padding(bs, indices, self.group_size, bid_num_cum)\n",
    "        indices_to_1 = self.indices_convert_from_to(indices2_group, indices1_group)\n",
    "        indices_to_2 = self.indices_convert_from_to(indices1_group, indices2_group)\n",
    "        return indices1_group, indices2_group, indices_to_1, indices_to_2\n",
    "\n",
    "\n",
    "class Layer(torch.nn.Module):\n",
    "    def __init__(self, input_channel, output_channels):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Identity()\n",
    "        self.linear2 = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, g, c = x.size()\n",
    "        loc = self.linear1(x.view(-1, c)).view(n, g, -1)\n",
    "        # glb = torch.nn.functional.max_pool2d(loc, kernel_size=(g, 1))\n",
    "        x = self.linear2(loc)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, group_size, cfg):\n",
    "        super().__init__()\n",
    "        model_list = []\n",
    "        for i in range(len(cfg) - 1):\n",
    "            model_list.append(Layer(cfg[i], cfg[i + 1]))\n",
    "        self.group_size = group_size\n",
    "        self.layers = torch.nn.Sequential(*model_list)\n",
    "\n",
    "    def group(self, x):\n",
    "        return x.view(-1, self.group_size, x.shape[-1])\n",
    "\n",
    "    def flatten(self, x):\n",
    "        return x.view(-1, x.shape[-1])\n",
    "\n",
    "    def forward(self, x1, i_to, i_from):\n",
    "        x1 = self.flatten(self.layers(self.group(x1)))\n",
    "        x2 = self.flatten(self.layers(self.group(x1[i_to])))\n",
    "        return x2, i_from, i_to\n",
    "\n",
    "\n",
    "class CurveBackBone(torch.nn.Module):\n",
    "    def __init__(self, group_size, mlps):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = torch.nn.ModuleList(\n",
    "            [Block(group_size, mlp) for mlp in mlps]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, i_to, i_from):\n",
    "        for block in self.blocks:\n",
    "            x, i_to, i_from = block(x, i_to, i_from)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cfg = Config.fromfile_py(\"configs/voxformer/voxformer_4x2_80e_kitti_3cls.py\")\n",
    "dataloader = build_dataloader(cfg.DATASET, cfg.RUN)\n",
    "model = build_detector(cfg.MODEL, dataset=dataloader.dataset).cuda()\n",
    "vfe = model.vfe\n",
    "batch_dict = next(iter(dataloader))\n",
    "dataloader.dataset.load_data_to_gpu(batch_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouper = VoxelGrouper(vfe.grid_size, 32)\n",
    "\n",
    "batch_dict = vfe(batch_dict)\n",
    "vox_feats = batch_dict['voxel_features']\n",
    "vox_coors = batch_dict['voxel_coords']\n",
    "vox_numbs = batch_dict['voxel_numbers']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rd3d.ops import sfc\n",
    "\n",
    "group_size = 32\n",
    "# indices = grouper(vox_coors)\n",
    "# out = indices_grouping(indices, vox_numbs, group_size)\n",
    "grid_size = torch.tensor((0, 2000, 2000, 2000)).cuda()\n",
    "for _ in range(1000):\n",
    "    with ScopeTimer(\"\", average=True, verbose=False) as t:\n",
    "        order = sfc.min_required_order(vox_coors)\n",
    "        vox_coors2 = vox_coors.detach().clone()\n",
    "        vox_coors2[:,1:]  = group_size-vox_coors2[:,1:]\n",
    "        vox_coors = torch.cat((vox_coors, vox_coors2)).int()\n",
    "        # codes = sfc.hilbert_curve_encoder(vox_coors, order)[None, :].view(2, -1)\n",
    "        # indices = torch.argsort(codes, dim=-1)\n",
    "        # out = sfc.indices_grouping(indices, vox_numbs, group_size)\n",
    "\n",
    "print(t.duration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from rd3d.ops.sfc import indices_grouping\n",
    "#\n",
    "# for i in range(10000):\n",
    "#     indices_grouping(indices, vox_numbs, group_size)\n",
    "# for i in range(10000):\n",
    "#     with ScopeTimer(\"grouping:\", average=True, verbose=False) as t:\n",
    "#         indices_grouping(indices, vox_numbs, group_size)\n",
    "#\n",
    "# print(t.duration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(indices.shape)\n",
    "# backbone = CurveBackBone(32, mlps).cuda()\n",
    "#\n",
    "# ind1, ind2, ind21, ind12 = grouper(vox_coors)\n",
    "#\n",
    "# vox_coors = vox_coors[ind1]\n",
    "# vox_feats = vox_feats[ind1]\n",
    "# vox_feats = backbone(vox_feats, ind12, ind21)\n",
    "# seg = PointSegmentor(c, 3, [c, c]).cuda()\n",
    "# seg(vox_coors, vox_feats)\n",
    "# seg.assign_targets(batch_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
