{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17 14:44:40,284 cfg INFO] import module at root: /home/nrsl/workspace/temp/voxformer\n",
      "[2023-12-17 14:44:40,284 cfg INFO] import module as config: configs.voxformer.voxformer_4x2_80e_kitti_3cls\n",
      "[2023-12-17 14:44:40,404 dataset INFO] Database filter by min points Car: 14357 => 13532\n",
      "[2023-12-17 14:44:40,405 dataset INFO] Database filter by min points Pedestrian: 2207 => 2168\n",
      "[2023-12-17 14:44:40,406 dataset INFO] Database filter by min points Cyclist: 734 => 705\n",
      "[2023-12-17 14:44:40,426 dataset INFO] Database filter by difficulty Car: 13532 => 10759\n",
      "[2023-12-17 14:44:40,431 dataset INFO] Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "[2023-12-17 14:44:40,433 dataset INFO] Database filter by difficulty Cyclist: 705 => 581\n",
      "[2023-12-17 14:44:40,440 dataset INFO] Loading KITTI dataset\n",
      "[2023-12-17 14:44:40,559 dataset INFO] Total samples for KITTI dataset: 3712\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "from rd3d.datasets import build_dataloader\n",
    "from rd3d.models import build_detector\n",
    "from rd3d.core import Config\n",
    "from rd3d import PROJECT_ROOT\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "acc = accelerate.Accelerator()\n",
    "cfg = Config.fromfile_py(\"configs/voxformer/voxformer_4x2_80e_kitti_3cls.py\")\n",
    "dataloader = build_dataloader(cfg.DATASET, cfg.RUN)\n",
    "model = build_detector(cfg.MODEL, dataset=dataloader.dataset).cuda()\n",
    "batch_dict = next(iter(dataloader))\n",
    "dataloader.dataset.load_data_to_gpu(batch_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T06:44:43.189463688Z",
     "start_time": "2023-12-17T06:44:37.879492618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1727, 32, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m:\u001B[94m17\u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m14 \u001B[0mbn = torch.nn.BatchNorm1d(\u001B[94m10\u001B[0m)                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m15 \u001B[0mvox_feats = linear(vox_feats)                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m16 \u001B[0m\u001B[96mprint\u001B[0m(vox_feats.shape)                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m17 vox_feats = bn(vox_feats)                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m18 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mpy\u001B[0m:\u001B[94m1130\u001B[0m in \u001B[92m_call_impl\u001B[0m                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1127 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# this function, and just call forward.\u001B[0m                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1128 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_pre_hooks \u001B[95mo\u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1129 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1130 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*\u001B[96minput\u001B[0m, **kwargs)                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1131 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1132 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1133 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m _global_backward_hooks:                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/modules/\u001B[0m\u001B[1;33mbatchno\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mrm.py\u001B[0m:\u001B[94m179\u001B[0m in \u001B[92mforward\u001B[0m                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m176 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.bias,                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m177 \u001B[0m\u001B[2m│   │   │   \u001B[0mbn_training,                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m178 \u001B[0m\u001B[2m│   │   │   \u001B[0mexponential_average_factor,                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m179 \u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.eps,                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m180 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m181 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m182 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/\u001B[0m\u001B[1;33mfunctional.py\u001B[0m:\u001B[94m2\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[94m439\u001B[0m in \u001B[92mbatch_norm\u001B[0m                                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2436 \u001B[0m\u001B[2m│   │   \u001B[0m_verify_batch_size(\u001B[96minput\u001B[0m.size())                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2437 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2438 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m torch.batch_norm(                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m2439 \u001B[2m│   │   \u001B[0m\u001B[96minput\u001B[0m, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2440 \u001B[0m\u001B[2m│   \u001B[0m)                                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2441 \u001B[0m                                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2442 \u001B[0m                                                                                          \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mRuntimeError: \u001B[0mrunning_mean should contain \u001B[1;36m32\u001B[0m elements not \u001B[1;36m10\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>bn = torch.nn.BatchNorm1d(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>vox_feats = linear(vox_feats)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(vox_feats.shape)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 vox_feats = bn(vox_feats)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">batchno</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">179</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   │   </span>bn_training,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   │   </span>exponential_average_factor,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>179 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.eps,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/nrsl/software/anaconda3/envs/torch112/lib/python3.7/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">439</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">batch_norm</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2436 │   │   </span>_verify_batch_size(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size())                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2437 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2438 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.batch_norm(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2439 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2440 │   </span>)                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2441 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2442 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>running_mean should contain <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> elements not <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vfe = model.vfe\n",
    "# bb3d = model.backbone_3d\n",
    "# batch_dict = vfe(batch_dict)\n",
    "# batch_dict = bb3d(batch_dict)\n",
    "batch_dict = model.vfe(batch_dict)\n",
    "vox_numbs = batch_dict['voxel_numbers']\n",
    "vox_coors = batch_dict['voxel_coords']\n",
    "vox_feats = batch_dict['voxel_features']\n",
    "ind, vox_nums = model.backbone_3d.mapping(vox_numbs, vox_coors)\n",
    "ind1, ind2, ind12, ind21 = ind\n",
    "vox_feats = vox_feats[ind1].view(-1, model.backbone_3d.group_size, vox_feats.size(-1))\n",
    "\n",
    "linear = torch.nn.Linear(vox_feats.size(-1), 10).cuda()\n",
    "bn = torch.nn.BatchNorm1d(10)\n",
    "vox_feats = linear(vox_feats)\n",
    "print(vox_feats.shape)\n",
    "# vox_feats = bn(vox_feats)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T06:52:37.463699047Z",
     "start_time": "2023-12-17T06:52:37.229730830Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
